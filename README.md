**DLProject â€” Character-Level Transformer Language Model**

This repository contains our implementation of the Deep Learning Mini Project for the course, where we build a decoder-only Transformer language model trained on the Tiny Shakespeare dataset.
The goal of the project is to understand and implement key components of the Transformer architecture from scratch, train the model, and generate Shakespeare like text.

**Repository Contents**
Below is a description of each file included:

DL-Mini project.pdf: Presentation slides- This PDF contains the final slides and forms the presentation portion of the project submission.

Instructions_file_miniproject2_language_model.ipynb: Official instructions provided by the professor

attempt1_Shakespearellm.ipynb:Initial attempt of the project which is the earlier version of the implementation. Kept for record but NOT the final version. Contains partial implementation and some corrections

mini_project_language_model.ipynb: FINAL submission notebook (complete and corrected implementation).This notebook contains the full working project and is the one for evaluation.

